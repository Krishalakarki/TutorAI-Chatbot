# TutorAI Chatbot â€” RAG-based Application
## Project Overview
A college PDF tutor chatbot that helps students learn from their own study materials. Upload PDFs (lecture notes, textbooks, assignments), and the AI answers your questions by retrieving the most relevant content before generating explanations.

## ğŸ§  What is RAG?
Retrieval-Augmented Generation (RAG) enhances a language model by first retrieving relevant context from a knowledge base.
This improves accuracy, prevents hallucinations, and is ideal for educational content like college notes and textbooks.

## ğŸ”„ Architecture
User uploads PDF
        â†“
PDF Loader â†’ Text Extraction â†’ Chunking
        â†“
Query Embedding â†’ Pinecone Vector DB (Hugging Face embeddings)
        â†“
Relevant Content Retrieved
        â†“
RAG Chain (Groq via LangChain)
        â†“
AI-generated Answer

## ğŸ“š Features

Upload college PDFs (notes, textbooks, assignments)

Auto-extracts text and splits into semantic chunks

Embeds chunks using Hugging Face embeddings (sentence-transformers/all-MiniLM-L6-v2)

Stores embeddings in Pinecone Vector DB 

Uses Groq (llama-3.1-8b-instant)for accurate responses

FastAPI backend with endpoints for file upload and asking questions

Streamlit frontend for interactive Q&A

## ğŸŒ Tech Stack
Component	   Tech Used
LLM	         Groq API (LLaMA3-70B)
Embeddings	 Hugging Face Embeddings
VectorDB   	 Pinecone
Framework	  LangChain
Backend	    FastAPI
Frontend	  Streamlit

##  API Endpoints
POST /upload_pdfs/ --- Upload one or more PDF files

POST /ask/ --- Ask a question --- Form field: `question`

## ğŸ“ Folder Structure
TutorAI/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”‚   â”œâ”€â”€ ask_question.cpython-313.pyc
â”‚   â”‚   â”‚   â””â”€â”€ upload_pdfs.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ ask_question.py
â”‚   â”‚   â””â”€â”€ upload_pdfs.py
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.cpython-313.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ load_vectorstore.cpython-313.pyc
â”‚   â”‚   â”‚   â””â”€â”€ query_handlers.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ llm.py
â”‚   â”‚   â”œâ”€â”€ load_vectorstore.py
â”‚   â”‚   â”œâ”€â”€ pdf_handlers.py
â”‚   â”‚   â””â”€â”€ query_handlers.py
â”‚   â”œâ”€â”€ middlewares/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”‚   â””â”€â”€ exception_handlers.cpython-313.pyc
â”‚   â”‚   â””â”€â”€ exception_handlers.py
â”‚   â”œâ”€â”€ uploaded_docs/
â”‚   â”‚   â”œâ”€â”€ Importance of Software Quality.pdf
â”‚   â”‚   â””â”€â”€ Software Quality.pdf
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ test.py
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â””â”€â”€ config.cpython-311.pyc
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”‚   â”œâ”€â”€ chatUI.cpython-311.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ history_download.cpython-311.pyc
â”‚   â”‚   â”‚   â””â”€â”€ upload.cpython-311.pyc
â”‚   â”‚   â”œâ”€â”€ chatUI.py
â”‚   â”‚   â”œâ”€â”€ history_download.py
â”‚   â”‚   â””â”€â”€ upload.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __pycache__/
â”‚       â”‚   â””â”€â”€ api.cpython-311.pyc
â”‚       â””â”€â”€ api.py
â”œ
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ main.py
â””â”€â”€ pyproject.toml


## âš¡ Quick Setup
# Clone the repo
$ git clone https://github.com/snsupratim/medicalAssistant.git
$ cd medicalAssistant/server

# Create virtual env
$ uv venv
$ .venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
$ uv pip install -r requirements.txt

# Set environment variables (.env)
GOOGLE_API_KEY=...
GROQ_API_KEY=...
PINECONE_API_KEY=...

# Run the server
$ uvicorn main:app --reload --port 8000


$ cd medicalAssistant/client

# Create virtual env
$ uv venv
$ .venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
$ uv pip install -r requirements.txt

# Run the server
$ streamlit run app.py

