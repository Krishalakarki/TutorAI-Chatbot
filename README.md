# TutorAI Chatbot â€” RAG-based Application
## Project Overview
A college PDF tutor chatbot that helps students learn from their own study materials. Upload PDFs (lecture notes, textbooks, assignments), and the AI answers your questions by retrieving the most relevant content before generating explanations.

## ğŸ§  What is RAG?
Retrieval-Augmented Generation (RAG) enhances a language model by first retrieving relevant context from a knowledge base.
This improves accuracy, prevents hallucinations, and is ideal for educational content like college notes and textbooks.

## ğŸ”„ Architecture
User uploads PDF
        â†“
PDF Loader â†’ Text Extraction â†’ Chunking
        â†“
Query Embedding â†’ Pinecone Vector DB (Hugging Face embeddings)
        â†“
Relevant Content Retrieved
        â†“
RAG Chain (Groq via LangChain)
        â†“
AI-generated Answer

## ğŸ“š Features

Upload college PDFs (notes, textbooks, assignments)

Auto-extracts text and splits into semantic chunks

Embeds chunks using Hugging Face embeddings (sentence-transformers/all-MiniLM-L6-v2)

Stores embeddings in Pinecone Vector DB 

Uses Groq (llama-3.1-8b-instant)for accurate responses

FastAPI backend with endpoints for file upload and asking questions

Streamlit frontend for interactive Q&A

## ğŸŒ Tech Stack
Component	   Tech Used
LLM	         Groq API (LLaMA3-70B)
Embeddings	 Hugging Face Embeddings
VectorDB   	 Pinecone
Framework	  LangChain
Backend	    FastAPI
Frontend	  Streamlit

##  API Endpoints
POST /upload_pdfs/ --- Upload one or more PDF files

POST /ask/ --- Ask a question --- Form field: `question`

## ğŸ“ Project Structure
```
TutorAI/
â”œâ”€â”€ server/                 # Backend FastAPI application
â”‚   â”œâ”€â”€ routes/            # API endpoints
â”‚   â”œâ”€â”€ modules/           # Core logic (LLM, vectorstore)
â”‚   â”œâ”€â”€ middlewares/       # Error handling
â”‚   â””â”€â”€ main.py           # Server entry point
â”œâ”€â”€ client/                # Frontend Streamlit application
â”‚   â”œâ”€â”€ components/        # UI components
â”‚   â”œâ”€â”€ utils/            # API client
â”‚   â””â”€â”€ app.py            # Client entry point
â””â”€â”€ pyproject.toml        # Project configuration
```


## âš¡ Quick Setup
# Clone the repo
git clone https://github.com/Krishalakarki/TutorAI-Chatbot.git
cd TutorAI/server

# Create virtual env
uv venv
.venv\Scripts\activate

# Install dependencies
uv pip install -r requirements.txt

# Set environment variables (.env)
GROQ_API_KEY=...
PINECONE_API_KEY=...
PINECONE_INDEX_NAME=..

# Run the server
uvicorn main:app --reload --port 8000


cd TutorAI/client


# Create virtual env
uv venv
.venv\Scripts\activate

# Install dependencies
$ uv pip install -r requirements.txt

# Run the server
$ streamlit run app.py

